use crate::dashboard::{Dashboard, DashboardItem, DashboardLayout};
use crate::pitch_plot::PitchPlot;
use crate::routes::{switch, Route};
use gloo::events::EventListener;
use js_sys::{Float32Array, Promise};
use log::info;
use std::collections::VecDeque;
use std::f64::consts::PI;
use wasm_bindgen::prelude::*;
use wasm_bindgen_futures::JsFuture;
use web_sys::{
    AnalyserNode, AudioContext, HtmlCanvasElement, MediaDevices, MediaStream,
    MediaStreamAudioSourceNode, MediaStreamConstraints, Navigator,
};
use yew::prelude::*;
use yew_router::prelude::*;

mod dashboard;
mod pitch_plot;
mod routes;

#[wasm_bindgen]
extern "C" {
    #[wasm_bindgen(js_namespace = navigator, js_name = mediaDevices)]
    pub static MEDIA_DEVICES: web_sys::MediaDevices;
}

// ğŸ¶ ì£¼ì–´ì§„ ì£¼íŒŒìˆ˜ë¥¼ ê°€ì¥ ê°€ê¹Œìš´ ìŒìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
fn frequency_to_note(freq: f64) -> &'static str {
    let notes = [
        "C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B",
    ];
    let a4 = 440.0;
    let n = ((freq / a4).log2() * 12.0).round();
    let index = (((n as isize) + 69) % 12) as usize;
    notes[index]
}

fn frequency_to_note_octave(freq: f64) -> String {
    let notes = [
        "C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B",
    ];
    let a4 = 440.0;
    let n = (12.0 * (freq / a4).log2()).round() as i32;
    let midi_number = n + 69;

    if midi_number < 24 || midi_number > 96 {
        return "Out of range".to_string(); // C1 ~ C6ì— í•´ë‹¹ (MIDI 24-96)
    }

    let note = notes[(midi_number % 12) as usize];
    let octave = midi_number / 12 - 1;

    format!("{}{}", note, octave)
}

fn analyze_pitch_autocorrelation(
    buffer: &[f32],
    sample_rate: f64,
    sensitivity: f32,
) -> Option<f64> {
    const MIN_FREQ: f64 = 32.0; // C1 ì£¼íŒŒìˆ˜ì— ê°€ê¹Œìš´ ê°’ (32.7Hz)
    const MAX_FREQ: f64 = 1050.0; // C6 ì£¼íŒŒìˆ˜ì— ê°€ê¹Œìš´ ê°’ (1046.5Hz)

    let rms = (buffer.iter().map(|&x| x * x).sum::<f32>() / buffer.len() as f32).sqrt();
    if rms < sensitivity {
        return None;
    }

    let min_lag = (sample_rate / MAX_FREQ) as usize;
    let max_lag = (sample_rate / MIN_FREQ) as usize;

    let mut best_lag = 0;
    let mut max_corr = 0.0;

    for lag in min_lag..=max_lag {
        let mut sum = 0.0;
        for i in 0..(buffer.len() - lag) {
            sum += buffer[i] * buffer[i + lag];
        }

        if sum > max_corr {
            max_corr = sum;
            best_lag = lag;
        }
    }

    if best_lag == 0 {
        return None;
    }

    let frequency = sample_rate / best_lag as f64;

    if frequency < MIN_FREQ || frequency > MAX_FREQ {
        return None;
    }

    Some(frequency)
}

// multi-frequency ë¶„ì„ í•¨ìˆ˜ ì¶”ê°€
fn analyze_multiple_frequencies(
    buffer: &[f32],
    sample_rate: f64,
    sensitivity: f32,
) -> Vec<(f64, f32)> {
    // RMS_THRESHOLD ëŒ€ì‹  ì „ë‹¬ëœ sensitivity ì‚¬ìš©
    // const RMS_THRESHOLD: f32 = 0.01;
    const MIN_FREQ: f64 = 32.0; // C1 ì£¼íŒŒìˆ˜ì— ê°€ê¹Œìš´ ê°’ (32.7Hz)
    const MAX_FREQ: f64 = 1050.0; // C6 ì£¼íŒŒìˆ˜ì— ê°€ê¹Œìš´ ê°’ (1046.5Hz)
    const PEAK_THRESHOLD: f32 = 0.7; // ìµœëŒ€ ìƒê´€ê´€ê³„ ëŒ€ë¹„ ì„ê³„ê°’
    const ABSOLUTE_MIN_FREQ: f64 = 30.0; // ê²€ì¶œ ê°€ëŠ¥í•œ ì ˆëŒ€ ìµœì†Œ ì£¼íŒŒìˆ˜ (C1ë³´ë‹¤ ì•½ê°„ ë‚®ê²Œ)
    const ABSOLUTE_MAX_FREQ: f64 = 1100.0; // ê²€ì¶œ ê°€ëŠ¥í•œ ì ˆëŒ€ ìµœëŒ€ ì£¼íŒŒìˆ˜ (C6ë³´ë‹¤ ì•½ê°„ ë†’ê²Œ)

    let rms = (buffer.iter().map(|&x| x * x).sum::<f32>() / buffer.len() as f32).sqrt();
    if rms < sensitivity {
        return Vec::new();
    }

    // ê²€ì¶œ ê°€ëŠ¥í•œ ì ˆëŒ€ ë²”ìœ„ë¡œ lag ë²”ìœ„ ê³„ì‚°
    let absolute_min_lag = (sample_rate / ABSOLUTE_MAX_FREQ).max(1.0) as usize;
    let absolute_max_lag = (sample_rate / ABSOLUTE_MIN_FREQ) as usize;

    // ë²„í¼ ê¸¸ì´ë³´ë‹¤ í° lagëŠ” ê³„ì‚°í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì œí•œ
    let absolute_max_lag = absolute_max_lag.min(buffer.len() - 1);

    // min_lagê°€ max_lagë³´ë‹¤ í¬ë©´ ê°’ì„ êµì²´í•˜ì—¬ ì˜¤ë¥˜ ë°©ì§€
    let (absolute_min_lag, absolute_max_lag) = if absolute_min_lag > absolute_max_lag {
        (1, absolute_min_lag.min(buffer.len() - 1))
    } else {
        (absolute_min_lag, absolute_max_lag)
    };

    // ìƒê´€ê´€ê³„ ê³„ì‚° ë²”ìœ„ëŠ” ë„“ê²Œ ì¡ë˜, ìœ íš¨ ì£¼íŒŒìˆ˜ íŒì •ì€ MIN_FREQ~MAX_FREQë¡œ ì œí•œ
    let target_min_lag = (sample_rate / MAX_FREQ) as usize;
    let target_max_lag = (sample_rate / MIN_FREQ) as usize;

    // ëª¨ë“  lagì— ëŒ€í•œ ìƒê´€ê´€ê³„ ê³„ì‚° (ë„“ì€ ë²”ìœ„)
    let mut correlations = Vec::with_capacity(absolute_max_lag + 1);
    correlations.push(0.0); // 0 lag ê°’

    for lag in 1..=absolute_max_lag {
        let mut sum = 0.0;
        for i in 0..(buffer.len() - lag) {
            sum += buffer[i] * buffer[i + lag];
        }
        correlations.push(sum);
    }

    // ëª¨ë“  lagì— ëŒ€í•œ ìƒê´€ê´€ê³„ ê°’ ì¤‘ ìµœëŒ“ê°’ ì°¾ê¸°
    let max_corr = if absolute_min_lag < absolute_max_lag {
        *correlations
            .iter()
            .skip(absolute_min_lag)
            .take(absolute_max_lag - absolute_min_lag)
            .max_by(|a, b| a.partial_cmp(b).unwrap())
            .unwrap_or(&0.0)
    } else {
        // min_lagê°€ max_lagë³´ë‹¤ í¬ê±°ë‚˜ ê°™ì€ ê²½ìš°
        0.0
    };

    // ì„ê³„ê°’ ì„¤ì •
    let threshold = max_corr * PEAK_THRESHOLD;

    // í”¼í¬ ì°¾ê¸° (ì „ì²´ ë²”ìœ„ì—ì„œ)
    let mut peaks = Vec::new();
    for lag in absolute_min_lag..=absolute_max_lag {
        let corr = correlations[lag];

        // ì£¼ë³€ ê°’ë³´ë‹¤ í°ì§€ í™•ì¸ (í”¼í¬ ì°¾ê¸°)
        if corr > threshold
            && (lag <= absolute_min_lag + 1 || corr > correlations[lag - 1])
            && (lag >= absolute_max_lag - 1 || corr > correlations[lag + 1])
        {
            let frequency = sample_rate / lag as f64;

            // ì£¼íŒŒìˆ˜ê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ëª…í™•íˆ í‘œì‹œ
            let amplitude = (corr / max_corr) as f32;

            if frequency >= MIN_FREQ && frequency <= MAX_FREQ {
                // ì •ìƒ ë²”ìœ„ ì£¼íŒŒìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ì¶”ê°€
                peaks.push((frequency, amplitude));
            } else {
                // ë²”ìœ„ ë°– ì£¼íŒŒìˆ˜ëŠ” íŠ¹ë³„íˆ í‘œì‹œ (ì§„í­ì— 0.5 ê³±í•˜ê¸°)
                // ì´ëŠ” UIì—ì„œ ë²”ìœ„ ë°– ì£¼íŒŒìˆ˜ë¥¼ í‘œì‹œí•˜ë˜ ì•½í•˜ê²Œ í‘œì‹œí•˜ëŠ”ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
                peaks.push((frequency, amplitude * 0.5));
            }
        }
    }

    // ì§„í­ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    peaks.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());

    peaks
}

// ğŸ¤ ì‹¤ì‹œê°„ í”¼ì¹˜ ë¶„ì„ê¸°
pub struct PitchAnalyzer {
    audio_ctx: Option<AudioContext>,
    analyser: Option<AnalyserNode>,
    _stream: Option<MediaStream>,
    pitch: String,
    prev_freqs: VecDeque<f64>,
    // ì—¬ëŸ¬ ì£¼íŒŒìˆ˜ë¥¼ ì €ì¥í•˜ëŠ” ì´ë ¥ - (timestamp, [(frequency, amplitude)])
    history: VecDeque<(f64, Vec<(f64, f32)>)>,
    canvas_ref: NodeRef,
    elapsed_time: f64,
    current_freq: f64,                        // ğŸ”¥ ê°€ì¥ ê°•í•œ ì£¼íŒŒìˆ˜
    sensitivity: f32,                         // ğŸšï¸ ë§ˆì´í¬ ì…ë ¥ ê°ë„ ì„¤ì •
    show_links: bool,                         // ğŸ”— ë§í¬ í‘œì‹œ ì—¬ë¶€
    mic_active: bool,                         // ğŸ¤ ë§ˆì´í¬ í™œì„±í™” ìƒíƒœ
    monitor_active: bool,                     // ğŸ”Š ë§ˆì´í¬ ëª¨ë‹ˆí„°ë§ í™œì„±í™” ìƒíƒœ
    speaker_node: Option<web_sys::AudioNode>, // ìŠ¤í”¼ì»¤ ì¶œë ¥ìš© ë…¸ë“œ
}

pub enum Msg {
    StartAudio,
    StopAudio,   // ğŸ”‡ ë§ˆì´í¬ ë¹„í™œì„±í™” ë©”ì‹œì§€ ì¶”ê°€
    ToggleAudio, // ğŸ¤ ë§ˆì´í¬ í™œì„±í™”/ë¹„í™œì„±í™” í† ê¸€
    UpdatePitch,
    AudioReady(AudioContext, AnalyserNode, MediaStream),
    UpdateSensitivity(f32),
    ToggleLinks,   // ğŸ”— ë§í¬ í‘œì‹œ ì—¬ë¶€ í† ê¸€
    ToggleMonitor, // ğŸ”Š ë§ˆì´í¬ ëª¨ë‹ˆí„°ë§ í† ê¸€
}

impl Component for PitchAnalyzer {
    type Message = Msg;
    type Properties = ();

    fn create(ctx: &Context<Self>) -> Self {
        // ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì¶”ê°€ - ì»¤ìŠ¤í…€ ì´ë²¤íŠ¸ ìˆ˜ì‹ 
        let link = ctx.link().clone();
        let window = web_sys::window().unwrap();
        let document = window.document().unwrap();

        // ë§ˆì´í¬ í† ê¸€ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
        let toggle_audio_callback = Callback::from(move |_: web_sys::Event| {
            link.send_message(Msg::ToggleAudio);
        });

        let toggle_audio_listener = EventListener::new(&document, "toggleAudio", move |e| {
            toggle_audio_callback.emit(e.clone());
        });

        // ê°ë„ ì¡°ì ˆ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
        let sensitivity_link = ctx.link().clone();
        let sensitivity_callback = Callback::from(move |e: web_sys::Event| {
            let custom_event = e.dyn_into::<web_sys::CustomEvent>().unwrap();
            let detail = custom_event.detail();
            let value = js_sys::Number::from(detail).value_of() as f32;
            sensitivity_link.send_message(Msg::UpdateSensitivity(value));
        });

        let sensitivity_listener = EventListener::new(&document, "updateSensitivity", move |e| {
            sensitivity_callback.emit(e.clone());
        });

        // ë§í¬ í† ê¸€ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
        let toggle_link = ctx.link().clone();
        let toggle_callback = Callback::from(move |_: web_sys::Event| {
            toggle_link.send_message(Msg::ToggleLinks);
        });

        let toggle_listener = EventListener::new(&document, "toggleLinks", move |e| {
            toggle_callback.emit(e.clone());
        });

        // ëª¨ë‹ˆí„°ë§ í† ê¸€ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
        let monitor_link = ctx.link().clone();
        let monitor_callback = Callback::from(move |_: web_sys::Event| {
            monitor_link.send_message(Msg::ToggleMonitor);
        });

        let monitor_listener = EventListener::new(&document, "toggleMonitor", move |e| {
            monitor_callback.emit(e.clone());
        });

        toggle_audio_listener.forget();
        sensitivity_listener.forget();
        toggle_listener.forget();
        monitor_listener.forget();

        Self {
            audio_ctx: None,
            analyser: None,
            _stream: None,
            pitch: "ğŸ¤ ìŒì„± ì…ë ¥ ëŒ€ê¸°...".to_string(),
            prev_freqs: VecDeque::with_capacity(5),
            history: VecDeque::new(),
            canvas_ref: NodeRef::default(),
            elapsed_time: 0.0,
            current_freq: 0.0,
            sensitivity: 0.01,     // ê¸°ë³¸ ê°ë„ ê°’
            show_links: true,      // ê¸°ë³¸ì ìœ¼ë¡œ ë§í¬ í‘œì‹œ
            mic_active: false,     // ì²˜ìŒì—ëŠ” ë§ˆì´í¬ ë¹„í™œì„±í™” ìƒíƒœ
            monitor_active: false, // ì²˜ìŒì—ëŠ” ëª¨ë‹ˆí„°ë§ ë¹„í™œì„±í™” ìƒíƒœ
            speaker_node: None,    // ìŠ¤í”¼ì»¤ ë…¸ë“œëŠ” ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ
        }
    }

    fn update(&mut self, ctx: &Context<Self>, msg: Self::Message) -> bool {
        match msg {
            Msg::StartAudio => {
                // ì´ë¯¸ í™œì„±í™”ëœ ê²½ìš° ë¬´ì‹œ
                if self.mic_active {
                    return false;
                }

                let link = ctx.link().clone();
                let mut constraints = MediaStreamConstraints::new();
                constraints.set_audio(&JsValue::TRUE);

                let user_media_promise = MEDIA_DEVICES
                    .get_user_media_with_constraints(&constraints)
                    .expect("Failed to request user media");

                wasm_bindgen_futures::spawn_local(async move {
                    match JsFuture::from(user_media_promise).await {
                        Ok(stream_value) => {
                            info!("got user media stream");
                            let stream = MediaStream::from(stream_value);
                            let audio_ctx =
                                AudioContext::new().expect("Failed to create AudioContext");
                            let analyser = audio_ctx
                                .create_analyser()
                                .expect("Failed to create AnalyserNode");
                            let source = audio_ctx
                                .create_media_stream_source(&stream)
                                .expect("Failed to create MediaStreamAudioSourceNode");

                            analyser.set_fft_size(2048);
                            source
                                .connect_with_audio_node(&analyser)
                                .expect("Failed to connect audio source");

                            // ë¶„ì„ê¸°, ìŠ¤íŠ¸ë¦¼, ì»¨í…ìŠ¤íŠ¸ë¥¼ Msgì— ë‹´ì•„ ë³´ëƒ„
                            link.send_message(Msg::AudioReady(audio_ctx, analyser, stream));
                        }
                        Err(err) => {
                            web_sys::console::log_1(&format!("Media error: {:?}", err).into());
                        }
                    }
                });

                false
            }

            Msg::UpdatePitch => {
                if let Some(analyser) = &self.analyser {
                    let mut buffer = vec![0.0f32; analyser.fft_size() as usize];
                    analyser.get_float_time_domain_data(&mut buffer[..]);
                    let sample_rate = 44100.0;

                    self.elapsed_time += 0.1;

                    // ì—¬ëŸ¬ ì£¼íŒŒìˆ˜ ë¶„ì„
                    let freqs =
                        analyze_multiple_frequencies(&buffer, sample_rate, self.sensitivity);

                    if !freqs.is_empty() {
                        // ê°€ì¥ ê°•í•œ ì£¼íŒŒìˆ˜ (ì²« ë²ˆì§¸ ìš”ì†Œ)
                        let strongest_freq = freqs[0].0;

                        // í‰ê·  ê³„ì‚°ì„ ìœ„í•´ ì´ì „ ëª©ë¡ì— ì¶”ê°€
                        if self.prev_freqs.len() >= 5 {
                            self.prev_freqs.pop_front();
                        }
                        self.prev_freqs.push_back(strongest_freq);
                        let average_freq =
                            self.prev_freqs.iter().sum::<f64>() / self.prev_freqs.len() as f64;
                        self.current_freq = average_freq;

                        let note = frequency_to_note_octave(average_freq);
                        self.pitch = format!("ğŸ¶ í˜„ì¬ ìŒ: {} ({:.2} Hz)", note, average_freq);

                        // ì „ì²´ ì£¼íŒŒìˆ˜ ëª©ë¡ ê¸°ë¡
                        self.history.push_back((self.elapsed_time, freqs));
                    } else {
                        self.pitch = "ğŸ”‡ ë„ˆë¬´ ì‘ì€ ì†Œë¦¬ (ë¬´ì‹œë¨)".to_string();
                        self.prev_freqs.clear();
                        self.current_freq = 0.0;

                        // ë¹ˆ ì£¼íŒŒìˆ˜ ëª©ë¡ ê¸°ë¡
                        self.history.push_back((self.elapsed_time, Vec::new()));
                    }

                    true
                } else {
                    false
                }
            }

            Msg::AudioReady(audio_ctx, analyser, stream) => {
                self.audio_ctx = Some(audio_ctx);
                self.analyser = Some(analyser);
                self._stream = Some(stream);
                self.mic_active = true;

                // ìŠ¤íŠ¸ë¦¼ ë³µì œ: í•˜ë‚˜ëŠ” ë¶„ì„ìš©, í•˜ë‚˜ëŠ” ëª¨ë‹ˆí„°ë§ìš©ìœ¼ë¡œ ë¶„ë¦¬
                if let Some(ctx) = &self.audio_ctx {
                    if let Some(stream) = &self._stream {
                        // ì›¹ ì˜¤ë””ì˜¤ ê·¸ë˜í”„ êµ¬ì„±:
                        // 1. ë§ˆì´í¬ ì…ë ¥ -> ë¶„ì„ê¸° (ë¶„ì„ ë°ì´í„° ìƒì„±)
                        // 2. ìŠ¤í”¼ì»¤ ì¶œë ¥ì€ í•„ìš”ì‹œ ë³„ë„ë¡œ ì—°ê²° (ToggleMonitorì—ì„œ ì²˜ë¦¬)
                        //
                        // ì´ë ‡ê²Œ í•˜ë©´ ë§ˆì´í¬ì™€ ìŠ¤í”¼ì»¤ê°€ ì„œë¡œ ë‹¤ë¥¸ ê²½ë¡œë¡œ ì²˜ë¦¬ë˜ì–´
                        // ì—ì½” ìº”ìŠ¬ë§ìœ¼ë¡œ ì¸í•œ ë¬¸ì œê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
                        web_sys::console::log_1(&"Audio graph configured for analysis".into());
                    }
                }

                let link = ctx.link().clone();
                gloo::timers::callback::Interval::new(100, move || {
                    link.send_message(Msg::UpdatePitch);
                })
                .forget();

                true
            }

            Msg::ToggleLinks => {
                self.show_links = !self.show_links;
                true
            }

            Msg::UpdateSensitivity(value) => {
                self.sensitivity = value;
                true
            }

            Msg::StopAudio => {
                // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì •ì§€
                if let Some(ctx) = &self.audio_ctx {
                    let _ = ctx.close();
                }

                // ìŠ¤íŠ¸ë¦¼ íŠ¸ë™ ì •ì§€
                if let Some(stream) = &self._stream {
                    let tracks = stream.get_audio_tracks();
                    for i in 0..tracks.length() {
                        let track_js = tracks.get(i);
                        let track = web_sys::MediaStreamTrack::from(track_js);
                        track.stop();
                    }
                }

                // ìƒíƒœ ì´ˆê¸°í™”
                self.audio_ctx = None;
                self.analyser = None;
                self._stream = None;
                self.mic_active = false;
                self.pitch = "ğŸ¤ ìŒì„± ì…ë ¥ ëŒ€ê¸°...".to_string();
                self.prev_freqs.clear();
                self.current_freq = 0.0;

                true
            }

            Msg::ToggleAudio => {
                if self.mic_active {
                    // ë§ˆì´í¬ê°€ í™œì„±í™”ëœ ìƒíƒœë©´ ë¹„í™œì„±í™”
                    ctx.link().send_message(Msg::StopAudio);
                } else {
                    // ë§ˆì´í¬ê°€ ë¹„í™œì„±í™”ëœ ìƒíƒœë©´ í™œì„±í™”
                    ctx.link().send_message(Msg::StartAudio);
                }

                false
            }

            Msg::ToggleMonitor => {
                // ë§ˆì´í¬ê°€ ë¹„í™œì„±í™” ìƒíƒœë¼ë©´ ëª¨ë‹ˆí„°ë§ì„ í•  ìˆ˜ ì—†ìŒ
                if !self.mic_active {
                    web_sys::console::log_1(
                        &"Cannot toggle monitor without active microphone".into(),
                    );
                    return false;
                }

                self.monitor_active = !self.monitor_active;

                if let (Some(audio_ctx), Some(analyser)) = (&self.audio_ctx, &self.analyser) {
                    if self.monitor_active {
                        // ëª¨ë‹ˆí„°ë§ í™œì„±í™”: ìƒˆë¡œìš´ ì—°ê²° ì„¤ì •
                        if let Some(stream) = &self._stream {
                            // ë¶„ì„ê¸° ë…¸ë“œë¥¼ ê·¸ëŒ€ë¡œ ë‘ê³ , ìŠ¤íŠ¸ë¦¼ì—ì„œ ìƒˆë¡œìš´ ì†ŒìŠ¤ ë…¸ë“œë¥¼ ìƒì„±
                            match audio_ctx.clone().create_media_stream_source(stream) {
                                Ok(monitor_source) => {
                                    // ê²Œì¸ ë…¸ë“œ ìƒì„±
                                    match audio_ctx.clone().create_gain() {
                                        Ok(gain_node) => {
                                            // ë³¼ë¥¨ ì„¤ì • (ë§ˆì´í¬ í”¼ë“œë°± ë°©ì§€ë¥¼ ìœ„í•´ ë‚®ê²Œ ì„¤ì •)
                                            let gain_param = gain_node.gain();
                                            gain_param.set_value(0.5);

                                            // ì†ŒìŠ¤ë¥¼ ê²Œì¸ ë…¸ë“œì— ì§ì ‘ ì—°ê²°
                                            if monitor_source
                                                .connect_with_audio_node(&gain_node)
                                                .is_err()
                                            {
                                                web_sys::console::log_1(
                                                    &"Failed to connect source to gain node".into(),
                                                );
                                                self.monitor_active = false;
                                                return false;
                                            }

                                            // ê²Œì¸ ë…¸ë“œë¥¼ ì¶œë ¥ì— ì—°ê²°
                                            if gain_node
                                                .connect_with_audio_node(
                                                    &audio_ctx.clone().destination(),
                                                )
                                                .is_err()
                                            {
                                                web_sys::console::log_1(
                                                    &"Failed to connect gain node to destination"
                                                        .into(),
                                                );
                                                self.monitor_active = false;
                                                return false;
                                            }

                                            // ìŠ¤í”¼ì»¤ ë…¸ë“œ ì €ì¥
                                            self.speaker_node = Some(gain_node.into());
                                            web_sys::console::log_1(
                                                &"Monitor activated with separate source".into(),
                                            );
                                        }
                                        Err(_) => {
                                            web_sys::console::log_1(
                                                &"Failed to create gain node".into(),
                                            );
                                            self.monitor_active = false;
                                            return false;
                                        }
                                    }
                                }
                                Err(_) => {
                                    web_sys::console::log_1(
                                        &"Failed to create monitor source".into(),
                                    );
                                    self.monitor_active = false;
                                    return false;
                                }
                            }
                        }
                    } else {
                        // ëª¨ë‹ˆí„°ë§ ë¹„í™œì„±í™”: ì—°ê²° í•´ì œ
                        if let Some(speaker_node) = &self.speaker_node {
                            // ì›¹ì˜¤ë””ì˜¤ APIëŠ” disconnect() ë©”ì„œë“œë¡œ ëª¨ë“  ì—°ê²°ì„ í•´ì œ
                            speaker_node.disconnect();
                            self.speaker_node = None;
                            web_sys::console::log_1(&"Monitor deactivated".into());
                        }
                    }
                    return true;
                }

                false
            }
        }
    }

    fn view(&self, ctx: &Context<Self>) -> Html {
        let current_freq = self.current_freq;
        let history = VecDeque::from(self.history.clone().into_iter().collect::<Vec<_>>());
        let show_links = self.show_links;

        // í”¼ì¹˜ í”Œë¡¯ ì»´í¬ë„ŒíŠ¸
        let pitch_plot = html! {
            <PitchPlot current_freq={current_freq} history={history} />
        };

        // ëŒ€ì‹œë³´ë“œ ë ˆì´ì•„ì›ƒ êµ¬ì„±
        let items = vec![DashboardItem {
            id: "pitch-plot".to_string(),
            component: pitch_plot,
            width: 2,
            height: 2,
            route: Some(Route::PitchPlot),
            show_link: self.show_links,
        }];

        let layout = DashboardLayout { items, columns: 3 };

        html! {
            <div class="app-container">
                <Dashboard layout={layout} />
            </div>
        }
    }
}

// Yew ì•± ì§„ì…ì 
#[function_component(App)]
fn app() -> Html {
    html! {
        <BrowserRouter>
            <Switch<Route> render={switch} />
        </BrowserRouter>
    }
}

// main í•¨ìˆ˜ ì •ì˜ (wasm ì•± ì§„ì…ì )
fn main() {
    wasm_logger::init(wasm_logger::Config::default());
    yew::Renderer::<App>::new().render();
}
